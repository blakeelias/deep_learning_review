{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jax_basics.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOUyP8WIfggXh1c8LQbFKVe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fs9uKMSilmet"},"outputs":[],"source":["import jax.numpy as jnp\n","from jax import grad, jit, vmap\n","from jax import random\n","from jax import nn\n","from matplotlib import pyplot as plt\n","import gzip"]},{"cell_type":"code","source":["!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"],"metadata":{"id":"cJu9b36amk4z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://stackoverflow.com/a/53570674\n","\n","def load_x(file_name):\n","  with gzip.open(file_name, 'r') as f:\n","    f.read(16)  # skip header\n","    buf = f.read()\n","    return jnp.frombuffer(buf, dtype=jnp.uint8).reshape(-1, 28, 28)\n","\n","def load_y(file_name):\n","  with gzip.open(file_name, 'r') as f:\n","    f.read(8)  # skip header\n","    buf = f.read()\n","    return jnp.frombuffer(buf, dtype=jnp.uint8)\n","\n","x_train = load_x('train-images-idx3-ubyte.gz').reshape(-1, 28*28) / 255\n","y_train = load_y('train-labels-idx1-ubyte.gz')\n","x_test = load_x('t10k-images-idx3-ubyte.gz').reshape(-1, 28*28) / 255\n","y_test = load_y('t10k-labels-idx1-ubyte.gz')"],"metadata":{"id":"BGG9O16qlpr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How big is our dataset? What kind of data do we have? \n","\n","print(x_train.shape, ', ', x_train.dtype)\n","print(y_train.shape, ', ', y_train.dtype)\n","print()\n","print(x_test.shape, ', ', x_test.dtype)\n","print(y_test.shape, ', ', y_test.dtype)"],"metadata":{"id":"UaIZ0tx6n0qn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Look at an example\n","# Images are monochrome with integer pixel values between 0 and 255 (inclusive)\n","\n","jnp.set_printoptions(linewidth=1000)\n","print(x_train[0].reshape(28, 28))"],"metadata":{"id":"pDTYVBi3n7dw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize some images and check their labels\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","for i in range(6):\n","  print(y_train[i])\n","  plt.imshow(x_train[i].reshape(28, 28))\n","  plt.show()\n","  print('')"],"metadata":{"id":"gjWk1dTtn-kb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the model"],"metadata":{"id":"_AD4-eT4odEv"}},{"cell_type":"code","source":["rkey = random.PRNGKey(0)\n","INPUT_DIM = x_train.shape[-1]\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 10\n","SCALE = 1e-2\n","\n","# Define and initialize the model parameters by sampling each element i.i.d. from a normal distribution\n","rkeys = random.split(rkey, 4)\n","W1 = SCALE * random.normal(rkey, (INPUT_DIM, HIDDEN_DIM))\n","W2 = SCALE * random.normal(rkey, (HIDDEN_DIM, OUTPUT_DIM))\n","B1 = SCALE * random.normal(rkey, (1, HIDDEN_DIM))\n","B2 = SCALE * random.normal(rkey, (1, OUTPUT_DIM))\n","\n","parameters = [W1, W2, B1, B2]\n","\n","\n","def relu(x):\n","  return jnp.maximum(0, x)\n","\n","def model_fn(x):\n","  h = relu(x @ W1 + B1)\n","  return h @ W2 + B2\n"],"metadata":{"id":"XzCrnh_kod4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mle_loss(logits, labels):\n","  log_probs = nn.log_softmax(logits, axis=1)\n","  selected = jnp.take_along_axis(log_probs, labels[:, None], axis=1)\n","  return -selected.mean()\n","\n","def regularizer(params):\n","  return sum(jnp.linalg.norm(p, 1) for p in params)  # regularization\n","\n","def accuracy(logits, target):\n","  argmaxs = jnp.argmax(logits, axis=1)\n","  corrects = jnp.equal(argmaxs, target)\n","  return corrects.mean()"],"metadata":{"id":"yek4nYBPpVmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forward(params, x, y, regularizer_weight):\n","  logits = model_fn(x)\n","  return mle_loss(logits, y) + regularizer_weight * regularizer(params)\n","\n","\n","@jit\n","def update(params, x, y, learning_rate, regularizer_weight):\n","  grads = grad(forward)(params, x, y, regularizer_weight)\n","  return [p - learning_rate * g for p, g in zip(params, grads)]"],"metadata":{"id":"uCKtM4sjcGUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 100\n","learning_rate = 1e-2\n","regularizer_weight = 1e-4\n","\n","for epoch in range(1000):\n","  idx = np.random.permutation(x_train.shape[0])  # random ordering of the training set\n","\n","  ## training step\n","  for i in range(0, x_train.shape[0], batch_size):\n","    x = x_train[idx[i:i+batch_size]]\n","    y = y_train[idx[i:i+batch_size]]\n","\n","    parameters = update(parameters, x, y, learning_rate, regularizer_weight)\n","\n","    if i % (batch_size * 100) == 0:\n","      loss_ = forward(parameters, x, y, regularizer_weight).tolist()\n","      print('Step:', i//batch_size, '; Loss:', loss_)\n","\n","  train_logits = model_fn(x_train)  # Training accurate\n","  test_logits = model_fn(x_test)  # Test accuracy\n","  print('')\n","  print('Epoch: %d | Train Accuracy: %.2f | Test Accuracy: %.2f' % (epoch, accuracy(train_logits, y_train).tolist(), accuracy(test_logits, y_test).tolist()))\n","  print('')"],"metadata":{"id":"AO80K0UPbU-E"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"feedforward_cnn.ipynb","provenance":[{"file_id":"1CYoriMHrNKbe484jg8IiykH0Rxt6p_vK","timestamp":1651182773870}],"collapsed_sections":[],"authorship_tag":"ABX9TyMDmXACLnEnlHhY5LY8BrfL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Reference: https://www.tensorflow.org/tutorials/quickstart/advanced"],"metadata":{"id":"j3YNMIXmQaiu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZx26blFKX9E"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","ks = tf.keras\n","print(\"TensorFlow version:\", tf.__version__)"]},{"cell_type":"markdown","source":["# Load the data"],"metadata":{"id":"dxS6l_MBK0IU"}},{"cell_type":"code","source":["# Download MNIST dataset into numpy tensors.\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train = x_train[..., None] / 255\n","x_test = x_test[..., None] / 255\n","y_train = np.int_(y_train)\n","y_test = np.int_(y_test)"],"metadata":{"id":"_VAs0HeZKpQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How big is our dataset? What kind of data do we have? \n","\n","print(x_train.shape, ', ', x_train.dtype)\n","print(y_train.shape, ', ', y_train.dtype)\n","print()\n","print(x_test.shape, ', ', x_test.dtype)\n","print(y_test.shape, ', ', y_test.dtype)"],"metadata":{"id":"IosFJ0g5Y_Ti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (x_train, y_train)).shuffle(10000).batch(batch_size)\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)"],"metadata":{"id":"xVCRFYgQQU85"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the model"],"metadata":{"id":"oXcwJFghK_rY"}},{"cell_type":"code","source":["# TODO: implement Dense and Conv2D layers myself"],"metadata":{"id":"Kp9uH4ZNamE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FFNN(ks.Model):\n","\n","  def __init__(self, output_size):\n","    super(FFNN, self).__init__()\n","    self.layers = [\n","        ks.layers.Dense(200, activation='relu'),\n","        ks.layers.Dense(100, activation='relu'),\n","        ks.layers.Dense(output_size)]\n","\n","  def call(self, x):\n","    x = x.reshape(tf.shape(x)[0], -1)\n","    for layer in self.layers:\n","      x = layer(x)\n","    return x"],"metadata":{"id":"kaDN4gieK6b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reference: https://www.tensorflow.org/tutorials/images/cnn\n","\n","class CNN(ks.Model):\n","\n","  def __init__(self, output_size):\n","    super(CNN, self).__init__()\n","    self.cnn_layers = [\n","        ks.layers.Conv2D(32, kernel_size=5, activation='relu'),\n","        ks.layers.Conv2D(64, kernel_size=5, activation='relu')]\n","    self.ff_layers = [\n","        ks.layers.Dense(200, activation='relu'),\n","        ks.layers.Dense(output_size)]\n","\n","  def call(self, x):\n","    for cnn_layer in self.cnn_layers:\n","      x = tf.nn.max_pool2d(cnn_layer(x), ksize=2, strides=1, padding='VALID')\n","    x = tf.reshape(x, (tf.shape(x)[0], -1))\n","    for ff_layer in self.ff_layers:\n","      x = ff_layer(x)\n","    return x"],"metadata":{"id":"c8Q-DWHOLJcz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: also demonstrate Sequential"],"metadata":{"id":"C5yILQI2aq4o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training loop"],"metadata":{"id":"3xfKMO3ba4Pp"}},{"cell_type":"code","source":["# TODO implement my own optimizer"],"metadata":{"id":"YyMmDxVY88b4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = 1e-3\n","batch_size = 32\n","\n","# model = FFNN(10)\n","model = CNN(10)\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True,  # predictions will be given as logits (log unnormalized probabilities) rather than probabilities\n",")\n","\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Use GPU if available.\n","# https://www.tensorflow.org/guide/gpu\n","GPUs = tf.config.list_physical_devices('GPU')\n","device = '/GPU:0' if GPUs else '/CPU:0'\n","print('device =', device)"],"metadata":{"id":"kiitl9yPl8Sn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    # training=True is only needed if there are layers with different\n","    # behavior during training versus inference (e.g. Dropout).\n","    logits = model(images, training=True)\n","    loss = loss_object(labels, logits)\n","    loss += 1e-3 * sum(tf.norm(p, 1) for p in model.trainable_variables)  # regularization\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  return loss, logits"],"metadata":{"id":"MGiAQomkVHuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def accuracy(logits, target, normalize=True):\n","  argmaxs = tf.math.argmax(logits, axis=1)\n","  corrects = tf.math.equal(argmaxs, target)\n","  count = tf.math.count_nonzero(corrects)\n","  if normalize:\n","    count = count / logits.shape[0]\n","  return count"],"metadata":{"id":"MZen2Bq0U24I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start tensorboard (optional)\n","# This will embed a tensorboard front-end in the output of this cell, which will display training graphs in realtime.\n","# See https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb\n","%load_ext tensorboard\n","%tensorboard --logdir logs"],"metadata":{"id":"sBJt-Ig59jlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tb_writer = tf.summary.create_file_writer('logs')  # Tensorboard writer\n","global_step = 0"],"metadata":{"id":"YCDuToqJAOzM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","  for i, (images, labels) in enumerate(train_ds):  \n","    # Move tensors to the configured device\n","    with tf.device(device):\n","      loss_, logits_ = train_step(images, labels)\n","    \n","    global_step += 1\n","\n","    if i % 100 == 0:\n","      loss_ = loss_.numpy()\n","      acc_ = accuracy(logits_, labels).numpy()\n","      print('  Step: %d | Train Loss: %.4f | Train Accuracy: %.2f' % (i, loss_, acc_))\n","      with tb_writer.as_default():\n","        tf.summary.scalar('train_loss', loss_, step=global_step)\n","        tf.summary.scalar('train_accuracy', acc_, step=global_step)\n","  \n","  with tf.device(device):\n","    loss_ = 0.0\n","    acc_ = 0.0\n","    for i, (x, y) in enumerate(test_ds):\n","      batch_logits_ = model(x)  # Test accuracy\n","      loss_ += loss_object(y, batch_logits_)\n","      acc_ += accuracy(batch_logits_, y).numpy()\n","    loss_ /= (i+1)\n","    acc_ /= (i+1)\n","\n","  # Save model checkpoint\n","  model.save(f'./training_checkpoints/ckpt_{epoch}')\n","\n","  print('')\n","  print('Epoch: %d | Test Loss: %.4f | Test Accuracy: %.2f' % (epoch, loss_, acc_))\n","  print('')\n","  with tb_writer.as_default():\n","    tf.summary.scalar('test_loss', loss_, step=global_step)\n","    tf.summary.scalar('test_accuracy', acc_, step=global_step)"],"metadata":{"id":"jGeGlGKTnACb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Manual save model\n","model.save(f'./training_checkpoints/ckpt_{epoch}')"],"metadata":{"id":"dlvZHXtyAzoP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load checkpoint\n","\n","Reference: https://www.tensorflow.org/guide/keras/save_and_serialize"],"metadata":{"id":"vCfo1d7kZ_eJ"}},{"cell_type":"code","source":["%ls training_checkpoints"],"metadata":{"id":"uB5WAypRZtdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_copy = ks.models.load_model('./training_checkpoints/ckpt_0')"],"metadata":{"id":"EFj7yQ9OaD12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_copy.compile()"],"metadata":{"id":"pcL9wdvfacKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device(device):\n","  loss_ = 0.0\n","  acc_ = 0.0\n","  for i, (x, y) in enumerate(test_ds):\n","    batch_logits_ = model_copy(x)  # Test accuracy\n","    loss_ += loss_object(y, batch_logits_)\n","    acc_ += accuracy(batch_logits_, y).numpy()\n","  loss_ /= (i+1)\n","  acc_ /= (i+1)\n","\n","print('Test Loss: %.4f | Test Accuracy: %.2f' % (loss_, acc_))"],"metadata":{"id":"kmB2tOy7ajR7"},"execution_count":null,"outputs":[]}]}